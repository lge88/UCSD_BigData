{
 "metadata": {
  "name": "",
  "signature": "sha256:c83270c6dd2040ba477676ba1cd49695019cba115ece9e3952f516e3583749a2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Overview of the Workflow ##\n",
      "1. **Count the Number of Measurements** \n",
      "\n",
      "    Count the number of valid records of TMIN and TMAX measurement for each station using MapReduce.\n",
      "    - Input: \n",
      "            s3://lge-bucket/weather-data/weather.csv\n",
      "    - Output: \n",
      "            station-measurement-counts.csv: station-id, number_of_TMIN_or_TMAX_records\n",
      "    - Implementation:\n",
      "            weather_data_parser.py: provides functions to parse the weather data.\n",
      "            mr_count_station_measurement.py\n",
      "            run_count_station_measurement.sh\n",
      "            \n",
      "2. **Join Stations and Weights** \n",
      "\n",
      "    Join the station data table with the number of valid records as a new column `weight'.\n",
      "    - Input: \n",
      "            s3://Weather.GHNC/stations.pkl.gz\n",
      "            station-measurement-counts.csv\n",
      "    - Output: \n",
      "            stations-lat-lon-weight.csv: station-id, latitude, longitude, weight\n",
      "    - Implementation:\n",
      "            join_station_with_weight.py\n",
      "            \n",
      "3. **Spatial Partitioning** \n",
      "\n",
      "    Run k-d tree partitioning for the stations based on the weighted station data.\n",
      "    - Input: \n",
      "            stations-lat-lon-weight.csv\n",
      "    - Output: \n",
      "            partition-tree.csv: node-id, coordinate (either 'lat' or 'lon'), threshold (value of latitude or longitude)\n",
      "            station-to-node.csv: station-id, node-id\n",
      "    - Implementation:\n",
      "            geo_partition.py\n",
      "            \n",
      "4. **Concat TMIN and TMAX vector** \n",
      "\n",
      "    For the same station the same year, concatenate TMIN (1 x 365) and TMAX (1 x 365) vector to form a 1 x 730 vector. This is done using MapReduce.\n",
      "    - Input: \n",
      "            s3://lge-bucket/weather-data/weather.csv\n",
      "    - Output: \n",
      "            s3://lge-bucket/weather-data/weather-tminmax/\n",
      "    - Implementation:\n",
      "            mr_concat_weather_tminmax.py\n",
      "            run_mr_concat_weather_tminmax.sh         \n",
      "\n",
      "5. **Compute Node Descriptors** \n",
      "\n",
      "    Compute the descriptor for each node at different level (0-9, 0 means the root level, 9 means leaf level) using MapReduce.\n",
      "    - Input: \n",
      "            s3://lge-bucket/weather-data/weather-tminmax/\n",
      "            station-to-node.csv\n",
      "    - Output: \n",
      "            s3://lge-bucket/weather-data/node-descriptor-k-n-dl/ (withot vector data)\n",
      "                Format: node-id, k, num_of_samples, descriptor_length\n",
      "                \n",
      "            s3://lge-bucket/weather-data/node-descriptor/ (full)\n",
      "                Format: node-id, k, num_of_samples, descriptor_length, [mu], [D_k], [U_k]\n",
      "                mu is the mean vector, 1 x 730.\n",
      "                D_k is the first k singular values, 1 x k.\n",
      "                U_k is the first k eigen vectors, k x 1 x 730.\n",
      "    - Implementation:\n",
      "            geo_partition.py: provides StationToNode data structure.\n",
      "            mr_weather_pca.py\n",
      "            run_mr_weather_pca.sh\n",
      "                \n",
      "6. **Merge Nodes based on Minimum Descriptor Length (MDL) Principle** \n",
      "\n",
      "    For given level, check each pair of children under the same parent, if the sum of descriptor length from the children is larger than the descriptor length of the parent, then the children should merge.\n",
      "    - Input: \n",
      "            s3://lge-bucket/weather-data/node-descriptor-k-n-dl/\n",
      "            partition-tree.csv\n",
      "    - Output: \n",
      "            partition-nodes-childen-should-merge-level-8.txt\n",
      "            partition-nodes-childen-should-merge-level-7.txt\n",
      "            ...\n",
      "            partition-nodes-childen-should-merge-level-0.txt\n",
      "\n",
      "            partition-nodes-childen-should-merge-level-N.txt:\n",
      "                Each line is the id of a node at level N, whose two childen should be merged.\n",
      "    - Implementation:\n",
      "            geo_partition.py\n",
      "            \n",
      "7. **Visualize Results** \n",
      "\n",
      "    Draw the stations as markers on google map. The station under the same node are drawn using the same color.\n",
      "    - Input: \n",
      "            stations-lat-lon-weight.csv\n",
      "            station-to-node.csv\n",
      "            node-descriptor-k-n-dl.csv\n",
      "            partition-tree.csv\n",
      "            partition-nodes-childen-should-merge-level-8.txt\n",
      "            partition-nodes-childen-should-merge-level-7.txt\n",
      "            ...\n",
      "            partition-nodes-childen-should-merge-level-0.txt\n",
      "    - Output: \n",
      "    [http://lge88.github.io/weather-map/](http://lge88.github.io/weather-map/)\n",
      "    - Implementation:\n",
      "    [https://github.com/lge88/weather-map](https://github.com/lge88/weather-map)           "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Results & Analysis ##"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Implementation ##"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}